[{"name": "API Monitoring", "id": "EAC0001", "description": "Monitor local APIs that might be used by adversary tools and activity.", "long_description": "API Monitoring involves capturing an internal OS function for its usage, accompanying arguments, and result. When a defender captures this information, the data gathered can be analyzed to gain insights into the activity of an adversary at a level deeper than normal system activity monitoring. This type of monitoring can also be used to produce high-fidelity detections. For example, the defender can trace activity through WinSock TCP API functions to view potentially malicious network events or trace usage of the Win32 DeleteFile() function to log all attempts at deleting a given file."}, {"name": "Network Monitoring", "id": "EAC0002", "description": "Monitor network traffic in order to detect adversary activity.", "long_description": "Network Monitoring involves capturing network activity data, including capturing server, firewall, and other relevant logs. A defender can send this data to a centralized collection location for further analysis. This analysis can be automated or manual. In either case, a defender can use Network Monitoring to identify anomalous traffic patterns, large or unexpected data transfers, and other activity that may reveal the presence of an adversary. \n<br><br>\nMonitoring is essential to maintain situational awareness of adversary activities to ensure operational safety and make progress towards the defender's goals. Careful pre-operational planning should be done to properly instrument the engagement environment to ensure that all key network traffic is collected. Some use cases of network monitoring include detecting unexpected outbound traffic, systems establishing connections using encapsulated protocols, and known adversary C2 protocols."}, {"name": "System Activity Monitoring", "id": "EAC0003", "description": "Collect system activity logs that can reveal adversary activity.", "long_description": "Capturing system logs can show logins, user and system events, etc. A defender can use such inherent system logging to study and collect first-hand observations about the adversary's actions and tools. \n<br><br>\nThis data can be sent to a centralized collection location for further analysis. Careful planning should be used to guide which system logs are collected and at what level. If the logging level is set too high or too many system logs are collected, the defender may be blinded by the excess data. For example, understanding the adversary's known TTPs will highlight resources the adversary is likely to touch and therefore which system logs are likely to capture adversary activity. \n<br><br>\nOverall, System Activity Monitoring is essential to maintain situational awareness of adversarial activities in order to ensure operational safety and progress towards operational goals. Careful pre-operational planning should be done to properly instrument the engagement environment. This will ensure that all key network traffic is collected."}, {"name": "Network Analysis", "id": "EAC0004", "description": "Analyze network traffic to gain intelligence on communications between systems.", "long_description": "Network analysis can be an automated or manual task to review communications between systems to expose adversary activity, such as C2 or data exfiltration traffic. This analysis is normally done by capturing and analyzing traffic on the wire or from previously collected packet capture. \n<br><br>\nWhen custom protocols are in use, defenders can leverage protocol decoder frameworks. These are customized code modules that can read network traffic and contextualize activity between the C2 operator and the implant. These frameworks are often required to process complex encryption ciphers and custom protocols into a human-readable format for an analyst to interpret. Decoder creation requires malware analysis of the implant to understand the design of the protocol. While a high level of technical maturity is required to create such a decoder, once created they are invaluable to the defender. \n<br><br>\nFor example, a defender can use a protocol decode to decrypt network capture data and expose an adversary's C2 or exfiltration activity. Not only does this data provide exquisite intelligence in regard to the adversary's communications channels and targeting preferences, but it also provides future opportunities for data manipulation to further operational goals."}, {"name": "Decoy Artifacts and Systems", "id": "EAC0005", "description": "Introduce impersonations to expand the scope of a deceptive story.", "long_description": "Decoy Artifacts and Systems allow the defender to increase the attack surface of their environment to expose more of the deception story. Additionally, they can be used to adjust the adversary\u2019s sense of ambiguity to increase or decrease their level of uncertainty towards the environment. Investigation of these decoy artifacts may introduce a resource cost on the adversary, enable or block the adversary's intended actions, encourage or discourage a specific action or response, etc. \n<br><br>\nDecoy artifacts can take a variety of forms including credentials, accounts, files/directories, browser extensions/bookmarks, system processes, etc. Decoy systems can be real, virtual, or simulated. They can be presented as one of a variety of IT devices, including user workstations, servers, networking systems, IOT (embedded devices), mobile devices, etc. Regardless of form, these decoy artifacts and systems provide a variety of opportunities for the defender. For example, decoy artifacts can be used as tripwires to produce a high-fidelity alert when accessed. \n<br><br>\nCareful planning should guide the creation and deployment of these tripwires to ensure effectiveness. For example, understanding the adversary's known TTPs will highlight which resources the adversary is likely to touch, and therefore where decoy artifacts should be placed. A thorough assessment of the defender's priority cyber assets and intellectual property should guide the placement of decoy artifacts used as tripwires. \n<br><br>\nA decoy artifact can provide several means to influence adversary activity. The following examples illustrate the powerful effects decoy artifacts and systems can have on the adversary. First, by planting decoy artifacts and systems that align with known adversary TTPs, the defender can influence adversary activities. For example, if a target adversary has a capability against a specific application, the defender can place this vulnerable application in the environment to motivate the adversary to exploit the decoy. \n<br><br>\nAs a second example, a defender may install AV or some other security or monitoring tool in a way that is easy for the adversary to remove. If an adversary removes the tool, they may be emboldened to act more openly believing they can\u2019t be monitored.  \n<br><br>\nThe defender can attempt to demotivate the adversary by strategically placing decoy artifacts. For example, a defender could place a selection of reverse engineering tools or monitoring applications on a known vulnerable target. This may sow confusion and raise ambiguity, demotivating the adversary\u2019s desire to go after that target even if it is vulnerable. \n<br><br>\nPlanting decoy artifacts and systems in the environment can influence the adversary to reveal the extent of successive campaigns against a target. For example, the defender can make and leak fake credentials both inside and outside of the network. The defender can then monitor for the use of these credentials. Then, when an adversary uses a fake credential, the defender will receive a high-fidelity alert. If the credentials are unique, a defender may be able to detect how and when an adversary collected the credentials. \n<br><br>\nFinally, decoy artifacts can be used to impose a resource cost on the adversary. For example, the defender can create an especially enticing, but excessively large, decoy file that is time and resource consuming to exfiltrate from the target."}, {"name": "Application Diversity", "id": "EAC0006", "description": "Present the adversary with a variety of installed applications and services.", "long_description": "Application Diversity presents an array of software targets to the adversary. On a single target, system defenders can configure multiple services or software applications. On a target network, defenders can present systems with a variety of OSs, OS versions, applications, and services. Application Diversity can be used to encourage engagement by offering a broad attack surface.\n<br><br>\n Additionally, diversity can increase the adversary's overall comfort level by adding to the believability of the environment. By monitoring adversary activity in a diverse environment, the defender can gain information on the adversary's capabilities and targeting preferences. For example, a defender can install one or more applications with a variety of patch levels to see how the adversary's response differs across versions. \n<br><br>\nAdditionally, a diverse set of applications provides a variety of avenues for the defender to present additional information throughout an operation. This information can be used to introduce additional attack surfaces, motivate or demotivate the adversary, or further the deception story. For example, if the adversary is close to uncovering something that might raise suspicion around a target, the defender can add an event to a shared calendar application or a message in a notes application that the system will be offline for scheduled maintenance. Having a variety of applications on the system provides the defender with multiple engagement avenues to handle whatever events happen during the course of the operation. "}, {"name": "Network Diversity", "id": "EAC0007", "description": "Use a diverse set of devices on the network to help establish the legitimacy of a decoy network.", "long_description": "Network Diversity involves the use of an assorted collection of network resources such as networking devices, firewalls, printers, phones, etc. Network Diversity can be used to encourage adversaries to engage by offering a broad attack surface. Additionally, diversity can increase the adversary's overall comfort level by adding to the believability of the environment. By monitoring adversary activity in a diverse environment, the defender can gain information on the adversary's capabilities and targeting preferences. For example, a defender can deploy a variety of network resources to identify which devices are targeted by the adversary."}, {"name": "Burn-In", "id": "EAC0008", "description": "Exercise a target system in a manner where it will generate desirable system artifacts.", "long_description": "Burn-In involves exercising the system to create desirable system artifacts such as web browsing history, file system usage, or the running of user applications. At times, Burn-In can be accomplished by simply letting a system or application run for an extended period of time. Other times, the defender engages with the environment to produce the Burn-In artifacts, such as when the defender logs into a decoy account or accesses a decoy website to generate session cookies and browser history. These tasks can be accomplished manually or via automated tooling.\n<br><br>\nBurn-In should occur pre-operation and continue as appropriate during the operation. The artifacts generated during the Burn-In process can reassure the adversary of the environment's legitimacy by creating an environment that more closely resembles a real, lived in, system or network."}, {"name": "Email Manipulation", "id": "EAC0009", "description": "Modify the flow of email in the environment.\n", "long_description": "Email Manipulation covers the various ways email flows in the environment can be affected. Email Manipulation can affect which mail appliances process mail flows, where mail is forwarded, or what mail is present in an inbox. A common use case for email manipulation is as a vector to introduce malware into the engagement environment. \n<br><br>\nSuspicious emails may be removed from production mailbox and placed into an inbox in an engagement environment. Then, any suspicious attachments or links could be detonated from within the environment. As another example, emails collected over a long period of time from a legitimate inbox outside the environment may be moved into the environment to reassure the adversary of the environment\u2019s legitimacy by creating a mailbox that more closely resembles a real, lived-in inbox."}, {"name": "Peripheral Management", "id": "EAC0010", "description": "Manage peripheral devices used on systems within the network for engagement purposes. ", "long_description": "Peripheral Management is the administration of peripheral devices used on systems within the engagement environment. A defender can choose to allow or deny certain types of peripherals from being used on systems to either motivate or demotivate adversary activity or to direct the adversary towards specific targets. Defenders can also introduce peripherals to an adversary-controlled system to see how the adversary reacts. For example, the defender can introduce external Wi-Fi adapters, USB devices, etc. to determine if adversaries attempt to use them for exfiltration purposes. \n<br><br>\nAdditionally, peripherals provide an avenue for the defender to present new or additional information to the adversary. This information can be used to introduce an additional attack surface, motivate or demotivate adversary activity, or to further the deception story. For example, the defender may include data on a connected USB device or stage an important conversation near an externally connected camera or microphone. Depending on the contents of this data, the adversary may be encouraged to take a specific action and/or reassured about the legitimacy of the environment."}, {"name": "Pocket Litter", "id": "EAC0011", "description": "Place data on a system to reinforce the legitimacy of the system or user.", "long_description": "Pocket Litter is data placed on a system to convince an adversary that the system and users are real. Pocket Litter can be used to establish a cognitive bias to raise the adversary's tolerance to weaknesses in the environment. Unlike Decoy Artifacts, Pocket Litter does not necessarily aim to encourage the adversary to take a specific action, but rather it supports the overall deception story.\n<br><br>\nPocket Litter can include documents, pictures, registry entries, installed software, log history, browsing history, connection history, and other user data that an adversary would expect to exist on a user's computer. For example, a defender might conduct a series of web searches to generate browser artifacts, or scatter a variety of photos and documents across the desktop to make the computer feel lived in."}, {"name": "Personas", "id": "EAC0012", "description": "Create fictitious human user(s) through a combination of planted data and revealed behavior patterns.", "long_description": "A Persona is used to establish background information about a victim to increase the believability of the target. To create a persona, the defender must develop a backstory and seed the environment with varying data in support of this story. Depending on the need for realism, the constructed persona can be supported by evidence of hobbies, social and professional interactions, consumer transactions, employment, browsing habits, etc.\n<br><br>\nIn addition to lending legitimacy to the environment, personas can be used to engage directly with adversaries, such as during phishing email exchanges. Additionally, personas can make changes to the environment during the operation, such as adding or removing a USB device or introducing new decoy documents or credentials."}, {"name": "Detonate Malware", "id": "EAC0013", "description": "Execute malware under controlled conditions to analyze its functionality.", "long_description": "Malware can be detonated in a controlled and safe environment. Clear goals and safety procedures should always be established before detonation to ensure that the operation is focused and safe. The malware can be detonated in an execution environment ranging from a somewhat sterile commercial malware execution appliance to a bespoke engagement environment crafted to support an extended engagement. \n<br><br>\nOutcomes of a malware detonation operation can include new IOCs collected during dynamic analysis, additional TTPs elicited by detonating the malware in a target rich environment, and/or negative impacts to the adversary and their operation. These outcomes can be used to produce new analytics for high-fidelity analytics."}, {"name": "Software Manipulation", "id": "EAC0014", "description": "Make changes to a system's software properties and functions to achieve a desired effect.", "long_description": "Software Manipulation allows a defender to alter or replace elements of the OS, file system, or any other software installed and executed on a system. These alterations can affect outputs, degrade effectiveness, and/or prevent the software from functioning altogether. For example, the defender can manipulate software by changing the output of commonly used discovery commands to hide legitimate systems and artifacts and/or reveal decoy artifacts and systems. \n<br><br>\nAlternatively, the defender can change the output of the password policy description for an adversary attempting to brute-force credentials. This manipulation may cause the adversary to waste resources brute-forcing passwords with inaccurate complexity requirements. If the defender wanted to degrade software effectiveness, they might weaken algorithms to expose data that is being archived, encoded, and/or encrypted. \n<br><br>\nFinally, to prevent software from functioning altogether, the defender may cause software typically used to delete data or hide adversary artifacts to fail. For some Software Manipulation use cases, it may be possible to make changes in such a way that adversary actions and legitimate user actions are handled differently. For example, the defender could show all files when viewed in a graphical application but hide files or introduce decoy files when viewed via a terminal command. This would allow legitimate users full access to the file system while adversaries using a reverse shell to access the target would see the manipulated the files."}, {"name": "Information Manipulation", "id": "EAC0015", "description": "Conceal and reveal both facts and fictions to support a deception story", "long_description": "Information Manipulation is used to support the deception story. Revealed facts and fictions can be used to adjust the adversary\u2019s trust in the environment. Concealed facts and fiction can be used to adjust the adversary\u2019s sense of uncertainty towards the environment. Revealed facts may include OS type and version, geographic location, hardware type and version, accounts, credentials, etc. Revealed fictions may include the content of decoy files, emails, messages, etc. Revealed facts and fictions may or may not be believed by the adversary.\n<br><br>\nIf an adversary believes a revealed fact or fiction, it may lend credibility to the environment or encourage a specific action. If an adversary is suspicious or does not believe a revealed fact or fiction, it may erode adversary trust in the environment. For example, if the adversary discovers that a collection of legitimate passwords all contain the phrase \"honeytoken\" or \"canarytoken\" they may lose trust in the legitimacy of the environment, even if the credentials are real and valid in the enterprise network. Conversely, if the adversary checks the timestamps on various files on the target and finds timestamps going back multiple years, they may trust that the environment is legitimate even if, in reality, the files are new and the timestamps were falsified. In this way, revealed facts and fictions can be used to adjust the adversary's trust in the environment in ways that support the defender's goals. \n<br><br>\nConcealed facts may include virtualized systems disguised as physical systems, monitoring software, or collection efforts. Concealed fictions may include an encrypted, interestingly named, decoy file or a partially deleted email thread referencing high value, but decoy, assets. Concealed facts and fictions may or may not be discovered by the adversary. If the adversary discovers a concealed fact or fiction, it may increase the ambiguity of the environment and affect the adversary's sense of uncertainty. \n<br><br>\nFor example, if an adversary discovers a hidden monitoring solution is deployed, they may feel less comfortable engaging with that specific target. Conversely, if the defender deploys a hidden monitoring solution with an intentional blind spot that the adversary discovers, the adversary may feel a decrease in ambiguity and take additional actions believing that they will be undetected. In this way, concealed facts and fictions can be used to adjust the ambiguity and affect the adversary's sense of uncertainty in ways that support the defender's goals."}, {"name": "Network Manipulation", "id": "EAC0016", "description": "Make changes to network properties and functions to achieve a desired effect.", "long_description": "Network Manipulation allows a defender to throttle network speeds, segment the network, maintain a unique IP addressing scheme, add a kill switch to cut off network access, etc. These types of manipulations can affect the adversary's ability to achieve their operational objectives by incurring an increased resource cost, forcing them to change tactics, or stopping them altogether. \n<br><br>\nFor example, a defender can limit the allowed ports or network requests to force the adversary to alter their planned C2 or exfiltration channels. As another example, a defender could allow or deny outbound SMB requests from a network to affect the success of forced authentication. Additionally, the defender can degrade network speeds and reliability to impose a resource cost as adversaries exfiltrate large quantities of data. Finally, a defender can block primary C2 domains and IPs to determine if the adversary has additional infrastructure. While there are a range of network manipulation options, in all cases, the defender has an opportunity to learn about or influence the adversaries operating in the environment."}, {"name": "Hardware Manipulation", "id": "EAC0017", "description": "Alter the hardware configuration of a system to limit what an adversary can do with the device.", "long_description": "Hardware Manipulation can include physical or configuration changes to the hardware in the environment. This manipulation can include physically removing a system's microphone, camera, on-board Wi-Fi adapter, etc. or using software controls to disable those devices. These types of manipulations can affect the adversary's ability to achieve their operational objectives by incurring an increased resource cost, forcing them to change tactics, or stopping them altogether. \n<br><br>\nHardware Manipulation is often required to maintain operational safety. For example, if the operation includes Detonating Malware using a laptop physically located in a shared space, it is likely that the defender will not have the ability to hide the legitimate conversations and individuals present in the space. Unless the defender has the ability to control the background sounds and visuals, it is likely too risky to leave the camera and microphone connected to the machine.\n"}, {"name": "Security Controls", "id": "EAC0018", "description": "Alter security controls to make the system more or less vulnerable to attack.", "long_description": "Manipulating Security Controls involves making configuration changes to a system's security settings including modifying Group Policies, disabling/enabling autorun for removable media, tightening or relaxing system firewalls, etc. Such security controls can be tightened to dissuade or prevent adversary activity. Conversely, security controls can be weakened or left overly permissive to encourage or enable adversary activity. \n<br><br>\nTightening security controls can typically be done by implementing any of the mitigations described in MITRE ATT&CK. See https://attack.mitre.org/mitigations/enterprise/ for a full list of mitigation strategies. While loosening security controls may seem obvious (i.e., simply don't employ a given mitigation strategy), there is an additional level of nuance that must be considered. Some security controls are considered so routine that its absence may be suspicious.\n<br><br>\n For example, completely turning off Windows Defender would likely raise the adversary's suspicion. However, it is possible to turn off Windows Defender in certain shared drives to encourage adversary activity in predetermined locations. Therefore, it will likely be far less suspicious to turn off Windows Defender in a single directory or share. When assessing the likelihood that removing a given security control is overly suspicious, it is important to consider how prevalent that security control is, the target adversary's sophistication, and the deception story."}, {"name": "Baseline", "id": "EAC0019", "description": "Identify key system elements to establish a baseline and be prepared to reset a system to that baseline when necessary.", "long_description": "To determine the system Baseline, the defender must identify software and configuration elements that are critical to a set of objectives. The defender must define the proper values and be prepared to reset a running system to its intended state. Reverting to a Baseline configuration can be essential when restoring an operational environment to a safe state or when looking to impose a cost on adversaries by preventing their activity.\n<br><br>\n For example, the defender can watch for an adversary to make changes in the environment and then revert the environment with the goal of either forcing the adversary to target elsewhere in the network or to display a new, possibly more advanced TTP. The baseline values will also be crucial post-operation when analyzing changes to the environment over time."}, {"name": "Isolation", "id": "EAC0020", "description": "Configure devices, systems, networks, etc. to contain activity and data, thus preventing the expansion an engagement beyond desired limits.", "long_description": "Using Isolation, a defender can limit the effectiveness and scope of malicious activity and/or lower exposure to unintended risks. When a system or resource is isolated, a defender can observe adversary behaviors or tools without allowing lateral movement. For example, a defender may detonate a piece of malware on an isolated system to perform dynamic analysis without risk to other network resources. \n<br><br>\nDetermining which systems should be isolated in an operation is a critical decision when calculating acceptable operational risk. However, if the adversary expects to find an entire corporate network but instead finds only an isolated system, they may not be interested in engaging with the target. Balancing acceptable risk, believability, and operational goals is essential when determining if or when a system should be isolated."}, {"name": "Migrate Attack Vector", "id": "EAC0021", "description": "Move a malicious link, file, or device from its intended location to a decoy system or network for execution/use.", "long_description": "When a defender Migrates an Attack Vector, the defender intercepts a malicious element and moves it to a safe environment, such as a decoy system within a decoy network, for continued engagement or analysis. A defender may choose to migrate attack vectors, which may appear in the form of phishing emails, suspicious email attachments, or malicious USBs. For example, a defender might move a suspicious attachment from a corporate inbox to an inbox on a system that, while in the corporate IP space, is completely segmented from the enterprise network. This segregated environment will allow the adversary to move laterally throughout the environment without risk to enterprise resources. \n<br><br>\nDetermining when an engagement should be moved to an engagement environment is a critical decision when calculating acceptable operational risk. However, if the adversary sent a custom malware sample to a phishing victim, but ultimately find themselves on an unrelated victim, they may be suspicious. Balancing this acceptable risk, believability, and operational goals is essential when determining if or when to migrate an attack vector."}, {"name": "Artifact Diversity", "id": "EAC0022", "description": "Present the adversary with a variety of network and system artifacts.", "long_description": "Artifact Diversity means presenting multiple network and system artifacts to the adversary including accounts, files/directories, credentials, logs, web browsing history, browser cookies, etc. These artifacts can be legitimate artifacts created as the result of natural usage over time or manually added to the environment by the defender. Artifact Diversity can be used to encourage the adversary to engage by offering a broad attack surface or can increase the adversary's overall comfort level by adding to the believability of the environment.\n<br><br>\nAdditionally, these artifacts can be decoy artifacts intended to elicit a specific response from the adversary. In any case, by monitoring adversary activity in a diverse environment, the defender can gain information on the adversary's capabilities and targeting preferences. For example, a defender can include a diverse set of accounts and credentials and then monitor to determine which accounts the adversary targets in the future."}, {"name": "Strategic Goal", "id": "SAC0001", "description": "Define the objective of the desired end-state of your adversary engagement operations.", "long_description": "The Strategic Goal is the big picture objective that drives all of the approaches and activities used in an adversary engagement operation. The Strategic Goal allows the defender to align all actions to reach the desired end-state. There are three high-level strategic goals in adversary engagement operations: to Expose adversaries on the network, to Affect adversaries on the network, or to Elicit new information about adversaries. \n<br><br>\nThese big strategic outcomes can support objectives such as protecting a specific high-value technology or person by exposing adversaries targeting that technology or person, protecting against insider threats by affecting the adversary's ability to steal sensitive data, or increasing the defender's understanding of the threat landscape by eliciting new adversary TTPs, etc. Every action taken in the planning, execution, and analysis of an operation should be aligned with the strategic goal. Therefore, it is important to define this goal early on. Input from any involved stakeholders should be considered when choosing the strategic goal.\n<br><br>\nNote, due to feedback received, this Activity will be renamed in the V1 release to disambiguate strategic operational outcomes from the Strategic Goals listed in the Matrix."}, {"name": "Persona Creation", "id": "SAC0002", "description": "Plan and create a fictitious human user through a combination of planted data and revealed behavior patterns in support of your strategic objectives", "long_description": "Persona Creation is the process of planning for and creating the personas required to support the deception story. This process should be informed by the previously generated threat model for the defender's target adversary. For example, if the adversary targets a specific industry, the persona might be created to look like someone who works in that industry. The persona outline should include basic information about the persona itself such as their name, their relationship to the environment (is it a work computer with no personal information? A personal computer with no work information? Some mix of both?), and geographic location. Often, and especially for a short-term engagement operation, these persona traits can be fairly broad. \n<br><br>\nFor example, it is unlikely that a persona used in a short-term ransomware detonation operation would require a lot of details to be effective. However, for a longer-term insider threat protection operation, the defender may need to create a persona with the online presence of a corporate employee, including name, birthday, address, etc. Many factors should be considered when determining how in-depth a persona should be, including adversary sophistication, defender resources, and deception story.\n<br><br>\nOnce the persona traits have been decided, the planning process should determine how these traits will manifest in the environment. For example, if the persona is named Jane Doe, then maybe that persona has a mailbox on her desktop for the email janedoe1234@example.com. Persona creation is important to running an operation, as personas are resource intensive to create and maintain and can reveal the ruse if discovered as fake by the adversary."}, {"name": "Storyboarding", "id": "SAC0003", "description": "Plan and create the deception story.", "long_description": "Storyboarding is the process of creating the deception story through a sequence of events, interactions, the persona's pattern of life, etc. A large part of Storyboarding is creating this pattern of life for the persona(s) using the system(s). The pattern of life can include behaviors such as using email or chat software, browsing the Internet, using system software, or physically moving the device (particularly important for mobile devices and laptops). \n<br><br>\nThe defender must determine how the Persona's behavior and other events in the environment will be generated. Personas may be generated automatically with tooling, manually with human operators, or some combination of both. The availability of defender resources may greatly impact the frequency of manually executing behaviors. \n<br><br>\nNot every action taken in the environment needs to be planned in advance. However, the defender should have a general idea of what actions will be taken. Setting up a storyboard early in the planning process will allow the operation to run smoothly, efficiently, and most importantly, consistently, regardless of operator, so as not to reveal the ruse."}, {"name": "Develop Threat Model", "id": "SAC0004", "description": "Identify, understand, and prioritize potential engagement targets.", "long_description": "Developing a Threat Model allows the potential target adversary to be identified and understood. This model should be informed by a combination of open and closed source research. It can be supplemented with internal and external threat intelligence feeds and information gleaned from previous operations. \n<br><br>\nAdditionally, in order to build the model, the defender must have a thorough understanding of themselves. Among other things, this includes their own organization, trusted partners, infrastructure, current security strengths and weaknesses, and critical cyber assets. This understanding will inform the threat modeling by outlining the defender's attack surface and highlighting areas that may be of particular interest to a given adversary. The threat model output from this analysis should include information about the adversary's TTPs, IOCs, victimology, and level of sophistication. \n<br><br>\nApplying the Strategic Goal to these models allows the defender to prioritize target adversaries. For example, if the defender's intended operational outcome is to expose adversaries on the network, the defender should prioritize adversaries that historically target their organization or similar organizations and have displayed TTPs that are likely to evade current defenses. Additionally, Storyboarding should use the threat model for the target adversary to anticipate what the adversary will do in the environment, how they will react to what they find, and what the defender plans to do in response. \n<br><br>\nOnce one or more adversaries have been selected as the target adversary, the corresponding threat model should guide the creation of the engagement environment and storyboard including hardware and software requirements, the required level of realism for Decoy Artifacts and Pocket Litter, and acceptable operational risk. For example, if the target adversary is known to use ransomware, then having a domain controller (DC) in the environment will be a requirement as most ransomware requires a DC in order to execute."}, {"name": "Define Exit Criteria", "id": "SAC0005", "description": "Define the set of events that would lead to the unnegotiable conclusion to the operation.", "long_description": "Exit Criteria are the event or sequence of events that are agreed to be the unnegotiable immediate pause or end to the operation. Sometimes, these events include the successful completion of the agreed upon strategic goals. Other times, these events may signify the operation has reached a hard stop. This is often because future operational safety cannot be guaranteed. Or events have occurred that outweigh the agreed upon acceptable risk. Finally, it may just be that if the adversary operates any longer, they may learn something the defender doesn't want them to know.\n<br><br>\nMultiple parties from the technical operations, threat intel, legal, and management perspectives should be included when Defining Exit Criteria. For example, if an adversary begins to use the engagement environment as a platform to operate against other targets, stakeholders may decide that the operation must be suspended until the unacceptable traffic can be blocked. Defining Exit Criteria is an essential step to ensure operational safety."}, {"name": "Hotwash", "id": "SAC0006", "description": "Review the retrospective of operational activities.", "long_description": "The Hotwash is the opportunity for the team to review the events of the operation to ensure progress towards strategic outcomes. This retrospective can include a review of the entire operational process from planning, implementation, engagement activity, and impact. In additional to the operation itself, the Hotwash is an important time to assess the communication and teamwork of the operations team and all contributing stakeholders. While a Hotwash should always occur at the end of an operation, periodic hotwashes during long-running operations are vital to ensure alignment and progress towards the Strategic Goal."}, {"name": "Refine Operation Activities", "id": "SAC0007", "description": "Update and improve the implementation of operational activities to better achieve the strategic goal.", "long_description": "Refine Operation Activities refers to the process of updating and improving the technical implementation of operational activities. Activities are the means by which defenders drive progress towards approaches and ultimately goals. Therefore, it is essential to continue to refine and improve these activities based on operational experiences. This refinement can inform future operations or be used to improve a running operation. For example, suppose a password that was intended to be easy to crack has stumped multiple brute-forcing sessions. It may be time to change the password to something simpler or reassess if that path for movement in the environment is still necessary."}, {"name": "Distill Intelligence", "id": "SAC0008", "description": "Turn raw data gained during an operation into actionable intelligence.", "long_description": "Distill Intelligence refers to the process of taking the raw data collected during an operation and producing actionable intelligence. This raw data can take the form of collected logs, PCAP, malware, etc. The process of analyzing data can rely on manual or automatic processing. \n<br><br>\nOne key method of Distilling Intelligence is the use of data analytics. Data analytics allows the defender to map the raw data collected during an operation to the adversary behavior that generated it. To remain useful at scale, automated analytics, such as behavioral analytics, are essential to produce meaningful intelligence. Intelligence produced during this step can be shared inside and outside of the organization, as appropriate, and used to inform threat models and refine operation activities."}, {"name": "Inform Threat Model", "id": "SAC0009", "description": "Update existing threat models based on intelligence gained during engagement operation.", "long_description": "Informing Threat Model refers to the act of updating existing models based on new intelligence learned during the adversary engagement operation. Updates may include revising knowledge of adversary TTPs, IOCs, etc. Whenever the threat model is updated, it is essential to revisit any operational decisions that were made using the old threat model. Revisiting operational decisions is particularly important when the update to the threat model is related to new TTPs. \n<br><br>\nFor example, suppose an adversary is observed demonstrating a previously unknown TTP. Any operation currently focused on this threat should be reassessed. Defenders should ensure that collection is adequate to monitor this new TTP and continue to ensure operational safety. When appropriate, sharing this updated threat model with the community will allow for greater collaboration and shared defense."}]